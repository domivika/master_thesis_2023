# Define paths to references and directories
reference = "/lustre1/project/stg_00096/references/GRCh38.alt-masked-V2/index/bwa-mem2/Homo_sapiens_assembly38_masked.fasta"
known_sites = "/staging/leuven/stg_00096/references/GRCh38.alt-masked-V2/annotation/snv_indel/gnomAD_v3.1.2/small-gnomad-common-GRCexcl.genomes.v3.1.2.sites.all.vcf.bgz"
GATK_path = "/staging/leuven/stg_00096/software/singularity/gatk_4.2.6.1.sif"
work_dir = "/staging/leuven/stg_00096/home/dkresa/data/bulk/230810_RPMI8402_Illumina_seq"
stage_dir = "/staging/leuven/stg_00096"
lustre_dir = "/lustre1/project/stg_00096"
scratch_dir = "/scratch/leuven/343/vsc34319"

# Define global wildcards
files = glob_wildcards("/staging/leuven/stg_00096/home/dkresa/ResolveOME/bulk/230810_RPMI8402_Illumina_seq/230825.NovaSeq2.FCA/1399/{sample}_L00{l}_R{r}_001.fastq.gz")
fq1 = glob_wildcards("/staging/leuven/stg_00096/home/dkresa/ResolveOME/bulk/230810_RPMI8402_Illumina_seq/230825.NovaSeq2.FCA/1399/{sample}_L00{l}_R1_001.fastq.gz")
fq2 = glob_wildcards("/staging/leuven/stg_00096/home/dkresa/ResolveOME/bulk/230810_RPMI8402_Illumina_seq/230825.NovaSeq2.FCA/1399/{sample}_L00{l}_R2_001.fastq.gz")
chrom = glob_wildcards("/staging/leuven/stg_00096/home/dkresa/data/bulk/230810_RPMI8402_Illumina_seq/Snakemake/contigs/chr{n}")

# Define output files
FastQC_output = expand("QC/1_premap/fastqc/{sample}_L00{l}_R{r}_001_fastqc.html", zip, sample=files.sample, l=files.l, r=files.r)
MultiQC_output = "QC/1_premap/multiqc/multiqc_report.html"
BWA_MEM2_output = expand("raw_bams/{sample}_L00{l}.bam", zip, sample=files.sample, l=files.l)
SortBAMs_output = expand("raw_bams/{sample}_L00{l}.sorted.bam", zip, sample=files.sample, l=files.l)
MarkDuplicatesSpark_output = expand("raw_bams/{sample}_L00{l}.sorted.marked.bam", zip, sample=files.sample, l=files.l)
BaseRecalibrator_output = expand("recalibrated/{sample}_L00{l}.recal_data.table", zip, sample=files.sample, l=files.l)
ApplyBQSR_output = expand("recalibrated/{sample}_L00{l}.sorted.marked.recal.bam", zip, sample=files.sample, l=files.l)
HaplotypeCaller_output = expand("gvcf/{sample}_L00{l}_chr{n}.g.vcf.gz", l=files.l, sample=files.sample, n=chrom.n)
GenomicsDBImport_output = expand("database/{sample}_L00{l}_chr{n}_gdb", l=files.l, sample=files.sample, n=chrom.n)
GenotypeGVCFs_output = expand("vcf/{sample}_L00{l}_chr{n}.vcf", l=files.l, sample=files.sample, n=chrom.n)
MergeVcfs_output = "vcf/merged.vcf"

# Define output reports
FastQC_report = expand("reports/FastQC/{sample}_L00{l}_R{r}_001.txt", zip, sample=files.sample, l=files.l, r=files.r)
MultiQC_report = "reports/MultiQC/MultiQC.txt"
BWA_MEM2_report = expand("reports/BWA_MEM2/{sample}_L00{l}.txt", zip, sample=files.sample, l=files.l)
SortBAMs_report = expand("reports/SortBAMs/{sample}_L00{l}.txt", zip, sample=files.sample, l=files.l)
MarkDuplicatesSpark_report = expand("reports/MarkDuplicatesSpark/{sample}_L00{l}.txt", zip, sample=files.sample, l=files.l)
BaseRecalibrator_report = expand("reports/BaseRecalibrator/{sample}_L00{l}.txt", zip, sample=files.sample, l=files.l)
ApplyBQSR_report = expand("reports/ApplyBQSR/{sample}_L00{l}.txt", zip, sample=files.sample, l=files.l)
HaplotypeCaller_report = expand("reports/HaplotypeCaller/{sample}_L00{l}_chr{n}.txt", l=files.l, sample=files.sample, n=chrom.n)
GenomicsDBImport_report = expand("reports/GenomicsDBImport/{sample}_L00{l}_chr{n}.txt", l=files.l, sample=files.sample, n=chrom.n)
GenotypeGVCFs_report = expand("reports/GenotypeGVCFs/{sample}_L00{l}_chr{n}.txt", l=files.l, sample=files.sample, n=chrom.n)
MergeVcfs_report = "reports/MergeVcfs.txt"

rule all:
    input:
        FastQC_output,
        FastQC_report,
        MultiQC_output,
        MultiQC_report,
        BWA_MEM2_output,
        BWA_MEM2_report,
        SortBAMs_output,
        SortBAMs_report,
        MarkDuplicatesSpark_output,
        MarkDuplicatesSpark_report,
        BaseRecalibrator_output,
        BaseRecalibrator_report,
        ApplyBQSR_output,
        ApplyBQSR_report,
        HaplotypeCaller_output,
        HaplotypeCaller_report,
        GenomicsDBImport_output,
        GenomicsDBImport_report,
        GenotypeGVCFs_output,
        GenotypeGVCFs_report,
        MergeVcfs_output,
        MergeVcfs_report

# Rule for quality control (FastQC):
rule FastQC:
    input:
        fq = "/staging/leuven/stg_00096/home/dkresa/ResolveOME/bulk/230810_RPMI8402_Illumina_seq/230825.NovaSeq2.FCA/1399/{sample}_L00{l}_R{r}_001.fastq.gz"
    output:
        zip = "QC/1_premap/fastqc/{sample}_L00{l}_R{r}_001_fastqc.zip",
        html = "QC/1_premap/fastqc/{sample}_L00{l}_R{r}_001_fastqc.html",
        task_done = "reports/FastQC/{sample}_L00{l}_R{r}_001.txt"
    threads: 12
    log:
       out = "logs/FastQC/{sample}_L00{l}_R{r}_001.out",
       err = "logs/FastQC/{sample}_L00{l}_R{r}_001.err"
    shell:
        """
        fastqc -o QC/1_premap/fastqc {input.fq} \
        1> {log.out} 2> {log.err}

        touch {output.task_done}
        """

# Rule for generating MultiQC report
rule MultiQC:
    input:
        report_files = FastQC_output,
        check_input = FastQC_report
    output:
        html_report = "QC/1_premap/multiqc/multiqc_report.html",
        task_done = "reports/MultiQC/MultiQC.txt"
    threads: 24
    log:
       out = "logs/MultiQC/MultiQC.out",
       err = "logs/MultiQC/MultiQC.err"
    shell:
        """
        multiqc QC/1_premap/fastqc -o QC/1_premap/multiqc \
        1> {log.out} 2> {log.err}

        touch {output.task_done}
        """

# Rule for running BWA MEM2 alignment
rule BWA_MEM2:
    input:
        report_files = MultiQC_output,
        check_input = MultiQC_report,
        fq1 = "/staging/leuven/stg_00096/home/dkresa/ResolveOME/bulk/230810_RPMI8402_Illumina_seq/230825.NovaSeq2.FCA/1399/{sample}_L00{l}_R1_001.fastq.gz",
        fq2 = "/staging/leuven/stg_00096/home/dkresa/ResolveOME/bulk/230810_RPMI8402_Illumina_seq/230825.NovaSeq2.FCA/1399/{sample}_L00{l}_R2_001.fastq.gz",
        ref = reference
    output:
        bam = "raw_bams/{sample}_L00{l}.bam",
        task_done = "reports/BWA_MEM2/{sample}_L00{l}.txt"
    threads: 24
    shell:
        """
        /lustre1/project/stg_00096/software/bwa-mem2-2.2.1_x64-linux/bwa-mem2 mem \
        -t {threads} \
        -M \
        -R "@RG\\tID:{wildcards.sample}\\tPL:ILLUMINA\\tSM:{wildcards.sample}" {input.ref} \
        {input.fq1} {input.fq2} \
        | samtools view -Sb -> {output.bam}

        touch {output.task_done}
        """

# Rule for sorting BAM files by queryname
rule SortBAMs:
    input:
        bam = "raw_bams/{sample}_L00{l}.bam",
        check_input = BWA_MEM2_report
    output:
        sorted_bam = "raw_bams/{sample}_L00{l}.sorted.bam",
        task_done = "reports/SortBAMs/{sample}_L00{l}.txt"
    threads: 24
    log:
       out = "logs/SortBAMs/{sample}_L00{l}.out",
       err = "logs/SortBAMs/{sample}_L00{l}.err"
    shell:
        """
        java -jar $EBROOTPICARD/picard.jar SortSam \
        -I {input.bam} \
        -O {output.sorted_bam} \
        --SORT_ORDER queryname \
        1> {log.out} 2> {log.err}

        touch {output.task_done}
        """
        
# Rule for marking duplicates
rule MarkDuplicatesSpark:
    input:
        bam = "raw_bams/{sample}_L00{l}.sorted.bam",
        check_input = SortBAMs_report
    output:
        marked_bam = "raw_bams/{sample}_L00{l}.sorted.marked.bam",
        task_done = "reports/MarkDuplicatesSpark/{sample}_L00{l}.txt"
    params:
        gatk = GATK_path,
        stage = stage_dir,
        lustre = lustre_dir
    threads: 24
    log:
       out = "logs/MarkDuplicatesSpark/{sample}_L00{l}.out",
       err = "logs/MarkDuplicatesSpark/{sample}_L00{l}.err"
    shell:
        """        
        singularity run --nv \
        -B {params.stage} \
        -B {params.lustre} \
        {params.gatk} gatk MarkDuplicatesSpark \
        -I {input.bam} \
        -O {output.marked_bam} \
        -M {output.marked_bam}.metrics.txt \
        1> {log.out} 2> {log.err}

        touch {output.task_done}
        """

# Rule for base quality score recalibration
rule BaseRecalibrator:
    input:
        marked_bam = "raw_bams/{sample}_L00{l}.sorted.marked.bam",
        ref = reference,
        dbsnp = known_sites,
        check_input = MarkDuplicatesSpark_report
    output:
        data_table = "recalibrated/{sample}_L00{l}.recal_data.table",
        task_done = "reports/BaseRecalibrator/{sample}_L00{l}.txt"
    params:
        gatk = GATK_path,
        stage = stage_dir,
        lustre = lustre_dir
    threads: 2
    log:
       out = "logs/BaseRecalibrator/{sample}_L00{l}.out",
       err = "logs/BaseRecalibrator/{sample}_L00{l}.err"
    shell:
        """
        singularity run --nv \
        -B {params.stage} \
        -B {params.lustre} \
        {params.gatk} gatk BaseRecalibrator \
        -I {input.marked_bam} \
        -R {input.ref} \
        --known-sites {input.dbsnp} \
        -O {output.data_table} \
        1> {log.out} 2> {log.err}

        touch {output.task_done}
        """

# Rule for applying base quality score recalibration
rule ApplyBQSR:
    input:
        marked_bam = "raw_bams/{sample}_L00{l}.sorted.marked.bam",
        recalibration_table = "recalibrated/{sample}_L00{l}.recal_data.table",
        ref = reference,
        check_input = BaseRecalibrator_report
    output:
        output_bam = "recalibrated/{sample}_L00{l}.sorted.marked.recal.bam",
        task_done = "reports/ApplyBQSR/{sample}_L00{l}.txt"
    params:
        gatk = GATK_path,
        stage = stage_dir,
        lustre = lustre_dir
    threads: 2
    log:
       out = "logs/ApplyBQSR/{sample}_L00{l}.out",
       err = "logs/ApplyBQSR/{sample}_L00{l}.err"
    shell:
        """
        singularity run --nv \
        -B {params.stage} \
        -B {params.lustre} \
        {params.gatk} gatk ApplyBQSR \
        -R {input.ref} \
        -I {input.marked_bam} \
        --bqsr-recal-file {input.recalibration_table} \
        -O {output.output_bam} \
        1> {log.out} 2> {log.err}

        touch {output.task_done}
        """

# Rule for haplotype calling
rule HaplotypeCaller:
    input:
        ref = reference,
        bam = "recalibrated/{sample}_L00{l}.sorted.marked.recal.bam",
        check_input = ApplyBQSR_report,
        chrom = "contigs/chr{n}"
    output:
        gvcfs = "gvcf/{sample}_L00{l}_chr{n}.g.vcf.gz",
        task_done = "reports/HaplotypeCaller/{sample}_L00{l}_chr{n}.txt"
    params:
        gatk = GATK_path,
        stage = stage_dir,
        lustre = lustre_dir
    threads: 2
    log:
       out = "logs/HaplotypeCaller/{sample}_L00{l}_chr{n}.out",
       err = "logs/HaplotypeCaller/{sample}_L00{l}_chr{n}.err"
    shell:
        """
        singularity run --nv \
        -B {params.stage} \
        -B {params.lustre} \
        {params.gatk} gatk --java-options "-Xmx15g" HaplotypeCaller \
        -R {input.ref} \
        -I {input.bam} \
        --intervals chr{wildcards.n} \
        -O {output.gvcfs} \
        -ERC GVCF \
        1> {log.out} 2> {log.err}

        touch {output.task_done}
        """

# Rule for GVCFs combining
rule GenomicsDBImport:
    input:
        ref = reference,
        check_input = HaplotypeCaller_report,
        sample = "gvcf/{sample}_L00{l}_chr{n}.g.vcf.gz"
    output:
        database_dir = directory("database/{sample}_L00{l}_chr{n}_gdb"),
        task_done = "reports/GenomicsDBImport/{sample}_L00{l}_chr{n}.txt"
    params:
        gatk = GATK_path,
        stage = stage_dir,
        lustre = lustre_dir,
        tmp = scratch_dir
    threads: 2
    log:
       out = "logs/GenomicsDBImport/{sample}_L00{l}_chr{n}.out",
       err = "logs/GenomicsDBImport/{sample}_L00{l}_chr{n}.err"
    shell:
        """
        singularity run --nv \
        -B {params.stage} \
        -B {params.lustre} \
        {params.gatk} gatk --java-options "-Xmx15g" GenomicsDBImport \
        --genomicsdb-workspace-path {output.database_dir} \
        -R {input.ref} \
        -V {input.sample} \
        --intervals chr{wildcards.n} \
        --genomicsdb-shared-posixfs-optimizations true \
        1> {log.out} 2> {log.err}

        touch {output.task_done}
        """

# Rule for joint genotyping
rule GenotypeGVCFs:
    input:
        ref = reference,
        check_input = GenomicsDBImport_report,
        database = "database/{sample}_L00{l}_chr{n}_gdb"
    output:
        vcf_per_chrom = "vcf/{sample}_L00{l}_chr{n}.vcf",
        task_done = "reports/GenotypeGVCFs/{sample}_L00{l}_chr{n}.txt"
    params:
        gatk = GATK_path,
        stage = stage_dir,
        lustre = lustre_dir
    threads: 2
    log:
       out = "logs/GenotypeGVCFs/{sample}_L00{l}_chr{n}.out",
       err = "logs/GenotypeGVCFs/{sample}_L00{l}_chr{n}.err"
    shell:
        """
        singularity run --nv \
        -B {params.stage} \
        -B {params.lustre} \
        {params.gatk} gatk --java-options "-Xmx15g" GenotypeGVCFs \
        -R {input.ref} \
        --genomicsdb-shared-posixfs-optimizations true \
        -V gendb://{input.database} \
        -O {output.vcf_per_chrom} \
        1> {log.out} 2> {log.err}

        find vcf/ -type f -name "*.vcf.gz" > vcf_files.list
        touch {output.task_done}
        """

# Rule for vcf merging
rule MergeVcfs:
    input:
        check_input= GenotypeGVCFs_report
    output:
        merged_vcf="vcf/merged.vcf",
        task_done="reports/MergeVcfs.txt"
    threads: 2
    params:
        vcf="vcf_files.list"
    log:
        out="logs/MergeVcfs/merged_vcf.out",
        err="logs/MergeVcfs/merged_vcf.err"
    shell:
        """
        java -jar $EBROOTPICARD/picard.jar MergeVcfs \
        -I {params.vcf} \
        -O {output.merged_vcf} \
        1> {log.out} 2> {log.err}

        touch {output.task_done}
        """